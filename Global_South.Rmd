---
title: "Mapping the Politics of the New Global South, Progress Update"
author: "Neeraj Sharma"
date: "7/31/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Introduction

I am working for Professor Mark Bradley in the History Department at the University of Chicago this summer on his research project, Mapping the Politics of the New Global South. 

# Setup

Prior to performing analysis on the data collected, it is necessary to prep the work environment so it contains all the packages necessary for exploration. 

## Load Packages

```{r}
# Relevant to data importation, structuring and visualization
library(tidyverse)
library(knitr)
library(readr)
library(here)

# Relevant to data formatting
library(lubridate)
library(countrycode)

# Relevant to text analysis
library(tidytext)
library(stringr)
library(SnowballC)
library(textclean)
```

## Import datasets

These datasets were produced through the corpus_maker.R script. The original source files are from Mikhaylov.

```{r}
unigrams_corpus_1970on <- read_tsv(here::here("Data", "unigrams_mikhaylov_project.tsv")) %>%
  select(Session, Year, Country, word, word_stem)

bigrams_corpus_1970on <- read_tsv(here::here("Data", "bigrams_mikhaylov_project.tsv")) %>%
  select(Session, Year, Country, first_word_stem, second_word_stem, word_stem)
```

## Glimpse at the content of the datasets

Unigrams

```{r}
kable(unigrams_corpus_1970on %>% slice(1:10))
```

Bigrams

```{r}
kable(bigrams_corpus_1970on %>% filter(Session == 25) %>% slice(1:10))
```

# Common Words by Decade

```{r}
UN_stop_words <- tibble(words = c("nation", 
                                  "unit", 
                                  "intern", 
                                  "countri", 
                                  "develop", 
                                  "peac",
                                  "world",
                                  "peopl",
                                  # Stops countries from counting their own names as very commonly repeated words. 
                                  # Stripping removes casing. This takes codelist from countrycode.
                                  strip(codelist$country.name.en)
                                  ))
```

```{r}
seventies_freq <- unigrams_corpus_1970on %>%
  filter(Year == 1970) %>%
  anti_join(UN_stop_words, by = c("word_stem" = "words")) %>%
  group_by(word_stem) %>%
  count(sort = TRUE) %>%
  arrange(desc(n)) %>%
  ungroup() %>%
  mutate(percent = n/sum(n))

ninties_freq <- unigrams_corpus_1970on %>%
  filter(Year == 1990) %>%
  anti_join(UN_stop_words, by = c("word_stem" = "words")) %>%
  group_by(word_stem) %>%
  count(sort = TRUE) %>%
  arrange(desc(n)) %>%
  ungroup() %>%
  mutate(percent = n/sum(n))

tens_freq <- unigrams_corpus_1970on %>%
  filter(Year == 2010) %>%
  anti_join(UN_stop_words, by = c("word_stem" = "words")) %>%
  group_by(word_stem) %>%
  count(sort = TRUE) %>%
  arrange(desc(n)) %>%
  ungroup() %>%
  mutate(percent = n/sum(n))

ggplot(data = seventies_freq %>% slice(1:10), mapping = aes(x = reorder(word_stem, n), y = n, label = n)) +
  geom_col() +
  geom_text(hjust = 1.5, fontface = "bold", color = "White") +
  coord_flip() +
  labs(title = "Most common words in 1970", x = "Words (Stemmed)", y = "Number of Mentions")

ggplot(data = ninties_freq %>% slice(1:10), mapping = aes(x = reorder(word_stem, n), y = n, label = n)) +
  geom_col() +
  geom_text(hjust = 1.5, fontface = "bold", color = "White") +
  coord_flip() +
  labs(title = "Most common words in 1990", x = "Words (Stemmed)", y = "Number of Mentions")

ggplot(data = tens_freq %>% slice(1:10), mapping = aes(x = reorder(word_stem, n), y = n, label = n)) +
  geom_col() +
  geom_text(hjust = 1.5, fontface = "bold", color = "White") +
  coord_flip() +
  labs(title = "Most common words in 2010", x = "Words (Stemmed)", y = "Number of Mentions")
```

# Looking at specific countries keywords changing over time

I was encouraged by Professor Bradley to investigate keyword trends over time in the following countries:

*Indonesia
*Algeria
*Kenya
*Mexico
*Egypt

Here is what emerged based on this analysis. 

```{r fig.height = 10, fig.width = 10}
indonesia_count_word_year <- unigrams_corpus_1970on %>%
  filter(Country == "Indonesia") %>%
  anti_join(UN_stop_words, by = c("word_stem" = "words")) %>%
#  mutate(Year = cut(Year, breaks=c(1970, 1975, 1980, 1985, 1990, 1995, 2000, 2005, 2010, 2015, 2018), right = FALSE)) %>%
  group_by(Year, word_stem) %>%
  count() %>%
  group_by(Year) %>%
  top_n(n = 5) %>%
  arrange(desc(n), .by_group = TRUE) %>%
  ungroup() %>%
#  mutate(Year = as.factor(Year)) %>%
  mutate(word_stem = as.factor(word_stem)) %>%
  slice(1:28)
#  slice(1:40)
indonesia_count_word_year

# paste(indonesia_count_word_year$word_stem, indonesia_count_word_year$n, sep = ", ")

ggplot(data = indonesia_count_word_year, mapping = aes(x = Year, y = n, label = word_stem)) +
  geom_col(aes(group = sort(word_stem, decreasing = TRUE)), color = "White", position = "dodge") +
  geom_text(position = position_dodge(0.9), aes(group = sort(word_stem, decreasing = TRUE), hjust = 1.5), color = "White") +
  labs(title = "ggplot with decreasing as the item") +
  coord_flip()

ggplot(data = indonesia_count_word_year, mapping = aes(x = Year, y = n, label = word_stem)) +
  geom_col(aes(group = sort(as.factor(word_stem), descending = TRUE)), color = "White", position = "dodge") +
  geom_text(position = position_dodge(0.9), aes(group = sort(as.factor(word_stem), descending = TRUE), hjust = 1.5), color = "White") +
  labs(title = "ggplot with descending as the item") +
  coord_flip()


ggplot(data = indonesia_count_word_year, mapping = aes(x = Year, y = n, label = word_stem)) +
  geom_col(aes(group = word_stem), color = "White", position = "dodge") +
  geom_text(position = position_dodge(0.9), aes(group = word_stem, hjust = 1.5), color = "White") +
  coord_flip()

```

```{r}
indonesia <- unigrams_corpus_1970on %>%
  filter(Country == "Indonesia") %>%
  anti_join(UN_stop_words, by = c("word_stem" = "words")) %>%
  group_by(word_stem) %>%
  count(sort = TRUE) %>%
  arrange(desc(n)) %>%
  ungroup() %>%
  mutate(percent = n/sum(n)) %>%
  slice(1:30)

algeria <- unigrams_corpus_1970on %>%
  filter(Country == "Algeria") %>%
  anti_join(UN_stop_words, by = c("word_stem" = "words")) %>%
  group_by(word_stem) %>%
  count(sort = TRUE) %>%
  arrange(desc(n)) %>%
  ungroup() %>%
  mutate(percent = n/sum(n)) %>%
  slice(1:30)

kenya <- unigrams_corpus_1970on %>%
  filter(Country == "Kenya") %>%
  anti_join(UN_stop_words, by = c("word_stem" = "words")) %>%
  group_by(word_stem) %>%
  count(sort = TRUE) %>%
  arrange(desc(n)) %>%
  ungroup() %>%
  mutate(percent = n/sum(n)) %>%
  slice(1:30)

mexico <- unigrams_corpus_1970on %>%
  filter(Country == "Mexico") %>%
  anti_join(UN_stop_words, by = c("word_stem" = "words")) %>%
  group_by(word_stem) %>%
  count(sort = TRUE) %>%
  arrange(desc(n)) %>%
  ungroup() %>%
  mutate(percent = n/sum(n)) %>%
  slice(1:30)

egypt<- unigrams_corpus_1970on %>%
  filter(Country == "Egypt") %>%
  anti_join(UN_stop_words, by = c("word_stem" = "words")) %>%
  group_by(word_stem) %>%
  count(sort = TRUE) %>%
  arrange(desc(n)) %>%
  ungroup() %>%
  mutate(percent = n/sum(n)) %>%
  slice(1:30)
```

# Sentiment Analysis

This is for a later time and wasn't the focus of this project update. I'm keeping this here just so I have it in my backpocket for when it does become important later on in the project. 

```{r}
# corpus_affin df only contains words that have affinities mapped to them
unigrams_corpus_affin <- unigrams_corpus_1970on %>% 
  inner_join(get_sentiments("afinn"), by = c("word_stem" = "word"))

bigrams_corpus_affin <- bigrams_corpus_1970on %>% 
  inner_join(get_sentiments("afinn"), by = c("first_word_stem" = "word")) %>%
  inner_join(get_sentiments("afinn"), by = c("second_word_stem" = "word")) %>%
  mutate(mean_sentiment = (value.x+value.y)/2)
```
